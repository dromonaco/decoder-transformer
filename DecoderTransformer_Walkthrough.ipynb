{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42947b03-cf35-4e16-8751-92e444006f28",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Overview\n",
    "\n",
    "| Step | Function to Call | What to Inspect |\n",
    "| :---- | :---- | :---- |\n",
    "| **1\\. Input** | forwardEmbedding | Shapes, verify vectors are non-zero. |\n",
    "| **2\\. Mask** | makeCausalMask | **Visualize:** Ensure it is a triangle. |\n",
    "| **3\\. Attention** | forwardMHADebug | **Visualize:** attnWeights. Are they focusing on relevant past words? |\n",
    "| **4\\. Norms** | forwardLayerNorm | Check Mean/StdDev (should be \\~0 and \\~1). |\n",
    "| **5\\. Prediction** | finalLayer | argmax of the last token. Is it a real word? |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef40789-1728-4d5d-a638-22f7ae0fe48f",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f94dc237-33b3-48a3-9800-780434e5d0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "{-# LANGUAGE OverloadedStrings #-}\n",
    "\n",
    "import Torch (DType, Device, Parameter, Tensor, asTensor, defaultOpts, makeIndependent, ones, ones', toDependent, zeros, zeros')\n",
    "import qualified Torch as Th\n",
    "import qualified Torch.Autograd as TA\n",
    "import qualified Torch.Functional as F\n",
    "import qualified Torch.Functional.Internal as FI\n",
    "import qualified Torch.NN as NN\n",
    "import qualified Torch.Optim as Optim\n",
    "import qualified Torch.Serialize as Serialize\n",
    "import qualified Data.Set.Ordered as OSet\n",
    "import qualified Control.Foldl as L\n",
    "import qualified Data.Text as T\n",
    "import Data.Maybe (fromMaybe)\n",
    "import Text.Printf\n",
    "import IHaskell.Display\n",
    "import DecoderTransformer\n",
    "\n",
    "-- 1. Define both files used during training\n",
    "let trainFile = \"rpg-training-tokenized.txt\"\n",
    "let evalFile = \"rpg-evaluation-tokenized.txt\"\n",
    "\n",
    "-- 2. Load both files\n",
    "vocabParts <- traverse buildVocabFromFile [trainFile, evalFile]\n",
    "\n",
    "-- 3. Merge them AND add the [PAD] token (Crucial step!)\n",
    "-- This matches the logic in your compiled program\n",
    "let vocab = L.fold (L.Fold (OSet.|<>) (OSet.singleton \"[PAD]\") id) vocabParts\n",
    "let vocabSize = OSet.size vocab\n",
    "\n",
    "-- 4. Initialize an empty model structure\n",
    "model <- initModel vocabSize\n",
    "\n",
    "-- 2. Load the trained weights from the file created by 'stack run'\n",
    "loadedTensors <- Serialize.load \"rpg_model.pt\"\n",
    "\n",
    "-- 3. Hydrate the model\n",
    "loadedParams <- mapM makeIndependent loadedTensors\n",
    "let trainedModel = Th.replaceParameters model loadedParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30c3e714-449a-4be7-9b67-e9758534a410",
   "metadata": {},
   "outputs": [],
   "source": [
    "{-# LANGUAGE RecordWildCards #-}\n",
    "\n",
    "forwardEmbedding :: TransformerModel -> Th.Tensor -> Th.Tensor\n",
    "forwardEmbedding TransformerModel {..} input = \n",
    "  let w = toDependent embedWeights\n",
    "      emb = F.embedding False False w paddingIdx input\n",
    "      \n",
    "      -- Get current sequence length from input shape [Batch, SeqLen]\n",
    "      currentSeqLen = Th.size 1 input\n",
    "      \n",
    "      -- Unwrap and Slice Positional Encoding\n",
    "      -- From: [1, 64, 64] -> To: [1, 5, 64]\n",
    "      fullPos = toDependent posEncoding\n",
    "      slicedPos = Th.sliceDim 1 0 currentSeqLen 1 fullPos\n",
    "      \n",
    "  in emb + slicedPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "613b635b-2f63-4071-9ad0-825048a51bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "{-# LANGUAGE RecordWildCards #-}\n",
    "\n",
    "-- Returns (Output, AttentionWeights)\n",
    "forwardMHADebug :: MultiHeadAttention -> Th.Tensor -> (Th.Tensor, Th.Tensor)\n",
    "forwardMHADebug MultiHeadAttention {..} x =\n",
    "  let \n",
    "      -- 1. Linear Projections\n",
    "      q = NN.forward mhaLinearQ x\n",
    "      k = NN.forward mhaLinearK x\n",
    "      v = NN.forward mhaLinearV x\n",
    "\n",
    "      headDim = mhaEmbedDim `Prelude.div` mhaHeads\n",
    "      batch = head (Th.shape x)\n",
    "      seqLength = Th.shape x !! 1\n",
    "\n",
    "      -- 2. Reshape\n",
    "      viewShape = [batch, seqLength, mhaHeads, headDim]\n",
    "      q' = F.transpose (F.Dim 1) (F.Dim 2) $ Th.reshape viewShape q\n",
    "      k' = F.transpose (F.Dim 1) (F.Dim 2) $ Th.reshape viewShape k\n",
    "      v' = F.transpose (F.Dim 1) (F.Dim 2) $ Th.reshape viewShape v\n",
    "\n",
    "      -- 3. Scores\n",
    "      kT = F.transpose (F.Dim 2) (F.Dim 3) k'\n",
    "      scoresRaw = F.matmul q' kT\n",
    "      dk = Th.asTensor (fromIntegral headDim :: Float)\n",
    "      scoresScaled = scoresRaw / F.sqrt dk\n",
    "\n",
    "      -- 4. Mask (Simplified for debug: Optional)\n",
    "      -- For simple visualization, we can skip the mask or apply it if needed.\n",
    "      -- If you want to see the triangle, include the masking logic here.\n",
    "      \n",
    "      -- 5. Softmax -> THIS IS THE HEATMAP\n",
    "      attnWeights = F.softmax (F.Dim 3) scoresScaled\n",
    "\n",
    "      -- 6. Context\n",
    "      context = F.matmul attnWeights v'\n",
    "      contextT = F.transpose (F.Dim 1) (F.Dim 2) context\n",
    "      contextReshaped = Th.reshape [batch, seqLength, mhaEmbedDim] contextT\n",
    "      \n",
    "      finalOut = NN.forward mhaLinearOut contextReshaped\n",
    "   in (finalOut, attnWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a40e538e-0280-4754-80b0-53677af4b6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Returns: (Output, SoftmaxWeights, RawScores, Q, K, V)\n",
    "forwardMhaInspect :: MultiHeadAttention -> Th.Tensor -> (Th.Tensor, Th.Tensor, Th.Tensor, Th.Tensor, Th.Tensor, Th.Tensor)\n",
    "forwardMhaInspect MultiHeadAttention {..} x =\n",
    "  let \n",
    "      -- 1. Linear Projections\n",
    "      q = NN.forward mhaLinearQ x\n",
    "      k = NN.forward mhaLinearK x\n",
    "      v = NN.forward mhaLinearV x\n",
    "\n",
    "      headDim = mhaEmbedDim `Prelude.div` mhaHeads\n",
    "      batch = head (Th.shape x)\n",
    "      seqLength = Th.shape x !! 1\n",
    "\n",
    "      -- 2. Reshape for Heads\n",
    "      viewShape = [batch, seqLength, mhaHeads, headDim]\n",
    "      q' = F.transpose (F.Dim 1) (F.Dim 2) $ Th.reshape viewShape q\n",
    "      k' = F.transpose (F.Dim 1) (F.Dim 2) $ Th.reshape viewShape k\n",
    "      v' = F.transpose (F.Dim 1) (F.Dim 2) $ Th.reshape viewShape v\n",
    "\n",
    "      -- 3. Raw Scores (Affinity)\n",
    "      kT = F.transpose (F.Dim 2) (F.Dim 3) k'\n",
    "      scoresRaw = F.matmul q' kT\n",
    "      \n",
    "      -- 4. Scaled Scores\n",
    "      dk = Th.asTensor (fromIntegral headDim :: Float)\n",
    "      scoresScaled = scoresRaw / F.sqrt dk\n",
    "\n",
    "      -- 4b. Apply Causal Mask\n",
    "      -- Shape: [Seq, Seq] broadcasted to [Batch, Heads, Seq, Seq]\n",
    "      mask = makeCausalMask seqLength (Th.device x) (Th.dtype x)\n",
    "      scoresMasked = scoresScaled + mask\n",
    "\n",
    "      -- 5. Softmax (Probability)\n",
    "      attnWeights = F.softmax (F.Dim 3) scoresMasked\n",
    "\n",
    "      -- 6. Context\n",
    "      context = F.matmul attnWeights v'\n",
    "      contextT = F.transpose (F.Dim 1) (F.Dim 2) context\n",
    "      contextReshaped = Th.reshape [batch, seqLength, mhaEmbedDim] contextT\n",
    "      \n",
    "      finalOut = NN.forward mhaLinearOut contextReshaped\n",
    "   in (finalOut, attnWeights, scoresRaw, q', k', v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91d5bfcc-a71d-4c82-8699-82961b771ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Helper: Create a Causal Mask (Upper Triangular = -inf)\n",
    "makeCausalMask :: Int -> Th.Device -> Th.DType -> Th.Tensor\n",
    "makeCausalMask sz dev dtype =\n",
    "  let -- Create a matrix of ones [sz, sz]\n",
    "      opts = Th.withDevice dev (Th.withDType dtype defaultOpts)\n",
    "      onesMat = ones [sz, sz] opts\n",
    "      \n",
    "      -- Create Upper Triangular mask (1s in upper triangle, 0s elsewhere)\n",
    "      -- Diag 1 means \"start one step above the main diagonal\"\n",
    "      upperTri = F.triu (F.Diag 1) onesMat\n",
    "\n",
    "      -- Convert 1s to -1e9, 0s to 0.0\n",
    "      negInf = -1e9 :: Float\n",
    "   in upperTri * asTensor negInf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ced6114b-8e2c-4c17-b683-5945f25a7415",
   "metadata": {},
   "outputs": [],
   "source": [
    "{-# LANGUAGE OverloadedStrings #-}\n",
    "\n",
    "-- A helper to visualize a 2D attention matrix as an HTML Table\n",
    "visualizeAttention :: Th.Tensor -> IO ()\n",
    "visualizeAttention t = do\n",
    "  -- Convert tensor to list of lists (assuming 2D [Seq, Seq])\n",
    "  let rows = (Th.asValue t :: [[Float]])\n",
    "  \n",
    "  -- Helper to generate the HTML for a single cell\n",
    "  let cell val = \n",
    "        let \n",
    "           -- Background: Blue with opacity matching the attention weight\n",
    "           bgStyle = printf \"background-color: rgba(0, 0, 255, %.2f)\" val :: String\n",
    "           \n",
    "           -- Text Color: White if background is dark/intense (> 0.5), Black otherwise\n",
    "           -- This prevents \"White Text on White Background\" issues for low values\n",
    "           textColor = if val > 0.5 then \"white\" else \"black\" :: String\n",
    "           \n",
    "        in printf \"<td style='%s; color: %s; width: 40px; height: 40px; border: 1px solid #ddd; text-align: center; font-size: 12px;'>%.2f</td>\" bgStyle textColor val\n",
    "  \n",
    "  let rowHtml r = \"<tr>\" ++ concatMap cell r ++ \"</tr>\"\n",
    "  let tableHtml = \"<table style='border-collapse: collapse; font-family: sans-serif;'>\" ++ concatMap rowHtml rows ++ \"</table>\"\n",
    "  \n",
    "  printDisplay $ Display [html tableHtml]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af1766b-e20e-4bac-9971-19536267f39f",
   "metadata": {},
   "source": [
    "### **Phase 1: The Input Stage (Shape Shifting)**\n",
    "\n",
    "Goal: Understand how text becomes geometry.  \n",
    "Key Concept: \\[Batch, Seq\\] $\\rightarrow$ \\[Batch, Seq, EmbedDim\\]\n",
    "\n",
    "1. **Inspect the Vocabulary:** Pick 5 words and find their indices manually.  \n",
    "2. **Run Embeddings:** Use your forwardEmbedding helper.  \n",
    "   * **Investigation:** Print the shape. It should be \\[1, 5, 64\\].  \n",
    "   * **Sanity Check:** Print embedding\\[0\\]\\[0\\] (the vector for the first word) and embedding\\[0\\]\\[1\\] (the second). They should be completely different sets of numbers.  \n",
    "3. **Positional Encoding:**  \n",
    "   * **Action:** Extract posEncoding from the model.  \n",
    "   * **Experiment:** Verify that the vector at position 0 is different from the vector at position 1\\. Without this, the model sees \"The dog bit the man\" and \"The man bit the dog\" as identical \"bags of words.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baa0c3d4-c554-4522-bd7a-b29762921b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,128,13,126,139]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1,5,64]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Embedding"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tensor Float [5] [-7.3626e-3,  3.7367e-2, -3.4854e-2, -9.8547e-2, -6.7193e-2]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tensor Float [5] [ 6.7673e-2, -2.2636e-4, -5.7980e-2,  1.9481e-3, -4.4925e-2]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Positional encoding"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1,5,64]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tensor Float [5] [-2.9523e-2, -1.7858e-2, -1.9255e-3, -1.4800e-2,  4.0148e-3]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tensor Float [5] [-3.7810e-3, -1.0424e-2,  1.2837e-2,  9.9363e-5, -1.9342e-2]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Embedding + Positional encoding"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1,5,64]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tensor Float [5] [-3.6886e-2,  1.9509e-2, -3.6780e-2, -0.1133   , -6.3179e-2]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tensor Float [5] [-3.6886e-2,  1.9509e-2, -3.6780e-2, -0.1133   , -6.3179e-2]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tensor Float [5] [ 6.3892e-2, -1.0651e-2, -4.5144e-2,  2.0474e-3, -6.4267e-2]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tensor Float [5] [ 6.3892e-2, -1.0651e-2, -4.5144e-2,  2.0474e-3, -6.4267e-2]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "{-# LANGUAGE OverloadedStrings #-}\n",
    "\n",
    "-- Indices of 5 words\n",
    "let fiveWords = [\"if\", \"else\", \"endif\", \"eval\", \"callp\"] :: [T.Text]\n",
    "let wordIdxs = map (\\w -> fromMaybe 0 (OSet.findIndex w vocab)) fiveWords\n",
    "print wordIdxs\n",
    "\n",
    "-- embedding shape\n",
    "let wordsTensor = Th.reshape [1,5] $ asTensor wordIdxs\n",
    "let weights = toDependent (embedWeights trainedModel)\n",
    "let emb = F.embedding False False weights 0 wordsTensor \n",
    "print (Th.shape emb)\n",
    "\n",
    "putStrLn \"Embedding\"\n",
    "\n",
    "-- \"if\" embedding\n",
    "let ifEmb = Th.select 0 0 $ Th.select 0 0 emb\n",
    "print $ Th.sliceDim 0 0 5 1 ifEmb\n",
    "\n",
    "-- \"else\" embedding\n",
    "let elseEmb = Th.select 0 1 $ Th.select 0 0 emb\n",
    "print $ Th.sliceDim 0 0 5 1 elseEmb\n",
    "\n",
    "putStrLn \"Positional encoding\"\n",
    "\n",
    "-- positional encoding\n",
    "let fullPosEnc = toDependent $ posEncoding trainedModel\n",
    "let posEnc = Th.sliceDim 1 0 5 1 fullPosEnc\n",
    "print $ Th.shape posEnc\n",
    "\n",
    "-- first word in sequence encoding\n",
    "let pos1 = Th.select 0 0 $ Th.select 0 0 posEnc\n",
    "print $ Th.sliceDim 0 0 5 1 pos1\n",
    "\n",
    "-- second word in sequence encoding\n",
    "let pos2 = Th.select 0 1 $ Th.select 0 0 posEnc\n",
    "print $ Th.sliceDim 0 0 5 1 pos2\n",
    "\n",
    "putStrLn \"Embedding + Positional encoding\"\n",
    "\n",
    "-- run forwardEmbedding\n",
    "let embWithPos = forwardEmbedding trainedModel wordsTensor\n",
    "print (Th.shape embWithPos)\n",
    "let ifEmbWithPos = Th.select 0 0 $ Th.select 0 0 embWithPos\n",
    "print $ Th.sliceDim 0 0 5 1 ifEmbWithPos\n",
    "print $ Th.sliceDim 0 0 5 1 (ifEmb + pos1)\n",
    "let elseEmbWithPos = Th.select 0 1 $ Th.select 0 0 embWithPos\n",
    "print $ Th.sliceDim 0 0 5 1 elseEmbWithPos\n",
    "print $ Th.sliceDim 0 0 5 1 (elseEmb + pos2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2651d92b-7736-442d-a90f-978c30c600d0",
   "metadata": {},
   "source": [
    "### **Phase 2: The Heart (Multi-Head Attention)**\n",
    "\n",
    "Goal: Understand how tokens \"talk\" to each other.  \n",
    "Key Concept: $Q, K, V$ and the Causal Mask.\n",
    "\n",
    "1. **Use forwardMHADebug:** Pass your embeddings from Phase 1 into this function.  \n",
    "2. **Inspect Q, K, V:**  \n",
    "   * We project the input \\[64\\] into three different spaces.  \n",
    "   * **Action:** Check that $Q$ and $K$ have the same dimensions (so they can be multiplied).  \n",
    "3. **The \"Raw\" Scores (Affinity):**  \n",
    "   * Modify forwardMHADebug to return scoresRaw (before Softmax).  \n",
    "   * **Visual:** If you visualize this, the values will be wild (large positives and negatives).  \n",
    "4. **The Causal Mask (The Triangle):**  \n",
    "   * **Visual:** Use visualizeAttention on the mask tensor itself. You **must** see a solid triangle of \\-inf (or very large negative numbers) in the upper right.  \n",
    "   * **Why:** This proves the model cannot \"cheat\" by looking at future words.  \n",
    "5. **The Probability Map (Softmax):**  \n",
    "   * **Visual:** Look at attnWeights. The rows must sum to 1.0. This tells you: *For the word at position 3, how much does it care about positions 0, 1, and 2?*\n",
    "\n",
    "What you are looking for here:\n",
    "1. Q vs K: These vectors should be different. If $Q \\approx K$, your model hasn't learned to separate \"Asking\" from \"Answering\".\n",
    "2. Raw vs Softmax:\n",
    "   * Raw: Can be positive or negative (e.g., 5.2, -9.1). High positive means \"look here\". High negative means \"ignore this\".\n",
    "   * Softmax: Must be between 0.0 and 1.0.\n",
    "3. The Map: Since you provided 5 specific words, does \"endif\" (index 2) look back at \"if\" (index 0)? If the model understands code structure, you might see a higher weight there!\n",
    "\n",
    "Look at the attention row for \"else\". Does it have a high value (bright color) in the column for \"if\"? That would confirm \"else\" is paying attention to \"if\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b455840-0345-4493-a360-31ee92c2b70e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "What's going on with the Q, K, V transformation"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1,5,64]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1,5,4,16]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1,4,5,16]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "shapes of: q, k, v, raw, weights, out"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1,4,5,16]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1,4,5,16]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1,4,5,16]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1,4,5,5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1,4,5,5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1,5,64]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Query Vector for word 'else' (Position 1):"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tensor Float [5] [-0.4223   , -0.2898   ,  0.5669   ,  0.4373   , -0.5407   ]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Key Vector for word 'if' (Position 0):"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tensor Float [5] [-0.1322   ,  1.8142e-2, -1.8296e-2,  4.5183e-2, -8.9592e-2]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Raw Score (How much 'else' likes 'if'):"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tensor Float []  8.8453e-2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Probability (After Softmax):"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tensor Float []  0.6105"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Attention Map (Head 0):"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table style='border-collapse: collapse; font-family: sans-serif;'><tr><td style='background-color: rgba(0, 0, 255, 1.00); color: white; width: 40px; height: 40px; border: 1px solid #ddd; text-align: center; font-size: 12px;'>1.00</td><td style='background-color: rgba(0, 0, 255, 0.00); color: black; width: 40px; height: 40px; border: 1px solid #ddd; text-align: center; font-size: 12px;'>0.00</td><td style='background-color: rgba(0, 0, 255, 0.00); color: black; width: 40px; height: 40px; border: 1px solid #ddd; text-align: center; font-size: 12px;'>0.00</td><td style='background-color: rgba(0, 0, 255, 0.00); color: black; width: 40px; height: 40px; border: 1px solid #ddd; text-align: center; font-size: 12px;'>0.00</td><td style='background-color: rgba(0, 0, 255, 0.00); color: black; width: 40px; height: 40px; border: 1px solid #ddd; text-align: center; font-size: 12px;'>0.00</td></tr><tr><td style='background-color: rgba(0, 0, 255, 0.61); color: white; width: 40px; height: 40px; border: 1px solid #ddd; text-align: center; font-size: 12px;'>0.61</td><td style='background-color: rgba(0, 0, 255, 0.39); color: black; width: 40px; height: 40px; border: 1px solid #ddd; text-align: center; font-size: 12px;'>0.39</td><td style='background-color: rgba(0, 0, 255, 0.00); color: black; width: 40px; height: 40px; border: 1px solid #ddd; text-align: center; font-size: 12px;'>0.00</td><td style='background-color: rgba(0, 0, 255, 0.00); color: black; width: 40px; height: 40px; border: 1px solid #ddd; text-align: center; font-size: 12px;'>0.00</td><td style='background-color: rgba(0, 0, 255, 0.00); color: black; width: 40px; height: 40px; border: 1px solid #ddd; text-align: center; font-size: 12px;'>0.00</td></tr><tr><td style='background-color: rgba(0, 0, 255, 0.44); color: black; width: 40px; height: 40px; border: 1px solid #ddd; text-align: center; font-size: 12px;'>0.44</td><td style='background-color: rgba(0, 0, 255, 0.27); color: black; width: 40px; height: 40px; border: 1px solid #ddd; text-align: center; font-size: 12px;'>0.27</td><td style='background-color: rgba(0, 0, 255, 0.29); color: black; width: 40px; height: 40px; border: 1px solid #ddd; text-align: center; font-size: 12px;'>0.29</td><td style='background-color: rgba(0, 0, 255, 0.00); color: black; width: 40px; height: 40px; border: 1px solid #ddd; text-align: center; font-size: 12px;'>0.00</td><td style='background-color: rgba(0, 0, 255, 0.00); color: black; width: 40px; height: 40px; border: 1px solid #ddd; text-align: center; font-size: 12px;'>0.00</td></tr><tr><td style='background-color: rgba(0, 0, 255, 0.29); color: black; width: 40px; height: 40px; border: 1px solid #ddd; text-align: center; font-size: 12px;'>0.29</td><td style='background-color: rgba(0, 0, 255, 0.21); color: black; width: 40px; height: 40px; border: 1px solid #ddd; text-align: center; font-size: 12px;'>0.21</td><td style='background-color: rgba(0, 0, 255, 0.23); color: black; width: 40px; height: 40px; border: 1px solid #ddd; text-align: center; font-size: 12px;'>0.23</td><td style='background-color: rgba(0, 0, 255, 0.27); color: black; width: 40px; height: 40px; border: 1px solid #ddd; text-align: center; font-size: 12px;'>0.27</td><td style='background-color: rgba(0, 0, 255, 0.00); color: black; width: 40px; height: 40px; border: 1px solid #ddd; text-align: center; font-size: 12px;'>0.00</td></tr><tr><td style='background-color: rgba(0, 0, 255, 0.23); color: black; width: 40px; height: 40px; border: 1px solid #ddd; text-align: center; font-size: 12px;'>0.23</td><td style='background-color: rgba(0, 0, 255, 0.16); color: black; width: 40px; height: 40px; border: 1px solid #ddd; text-align: center; font-size: 12px;'>0.16</td><td style='background-color: rgba(0, 0, 255, 0.18); color: black; width: 40px; height: 40px; border: 1px solid #ddd; text-align: center; font-size: 12px;'>0.18</td><td style='background-color: rgba(0, 0, 255, 0.22); color: black; width: 40px; height: 40px; border: 1px solid #ddd; text-align: center; font-size: 12px;'>0.22</td><td style='background-color: rgba(0, 0, 255, 0.21); color: black; width: 40px; height: 40px; border: 1px solid #ddd; text-align: center; font-size: 12px;'>0.21</td></tr></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let firstBlock = head (layers trainedModel)\n",
    "let mhaLayer = attention firstBlock\n",
    "\n",
    "putStrLn \"What's going on with the Q, K, V transformation\"\n",
    "let numHeads = mhaHeads mhaLayer\n",
    "    headDim = mhaEmbedDim mhaLayer `Prelude.div` numHeads\n",
    "    batch = head (Th.shape embWithPos)\n",
    "    seqLength = Th.shape embWithPos !! 1\n",
    "let qRaw = NN.forward (mhaLinearQ mhaLayer) embWithPos\n",
    "print $ Th.shape qRaw\n",
    "let viewShape = [batch, seqLength, numHeads, headDim]\n",
    "let qRawReshaped = Th.reshape viewShape qRaw\n",
    "print $ Th.shape qRawReshaped\n",
    "let qRawTransposed = F.transpose (F.Dim 1) (F.Dim 2) qRawReshaped\n",
    "print $ Th.shape qRawTransposed\n",
    "\n",
    "-- 1. Run the inspection pass\n",
    "-- We use the 'mhaLayer' you extracted earlier and your 'embWithPos'\n",
    "let (out, weights, raw, q, k, v) = forwardMhaInspect mhaLayer embWithPos\n",
    "\n",
    "putStrLn \"shapes of: q, k, v, raw, weights, out\"\n",
    "print $ Th.shape q\n",
    "print $ Th.shape k\n",
    "print $ Th.shape v\n",
    "print $ Th.shape raw\n",
    "print $ Th.shape weights\n",
    "print $ Th.shape out\n",
    "\n",
    "-- 2. Inspect Q vs K (The \"Query\" and \"Key\")\n",
    "-- Pick Head 0, Batch 0\n",
    "-- Shape: [SeqLen, HeadDim]\n",
    "let q0 = Th.select 0 0 (Th.select 0 0 q)\n",
    "let k0 = Th.select 0 0 (Th.select 0 0 k)\n",
    "\n",
    "putStrLn \"Query Vector for word 'else' (Position 1):\"\n",
    "print $ Th.sliceDim 0 0 5 1 (Th.select 0 1 q0) \n",
    "\n",
    "putStrLn \"Key Vector for word 'if' (Position 0):\"\n",
    "print $ Th.sliceDim 0 0 5 1 (Th.select 0 0 k0)\n",
    "\n",
    "-- 3. Visualizing the \"Raw Affinity\" (Pre-Softmax) vs \"Probability\" (Post-Softmax)\n",
    "let raw0 = Th.select 0 0 (Th.select 0 0 raw)\n",
    "let w0   = Th.select 0 0 (Th.select 0 0 weights)\n",
    "\n",
    "putStrLn \"Raw Score (How much 'else' likes 'if'):\"\n",
    "-- Row 1 (\"else\"), Column 0 (\"if\")\n",
    "print $ Th.select 0 0 (Th.select 0 1 raw0)\n",
    "\n",
    "putStrLn \"Probability (After Softmax):\"\n",
    "print $ Th.select 0 0 (Th.select 0 1 w0)\n",
    "\n",
    "-- 4. See the whole map\n",
    "putStrLn \"Attention Map (Head 0):\"\n",
    "visualizeAttention w0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4ee0df-8d0e-468f-811f-b92fea07ad20",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Phase 3: The Body (Feed Forward & Norms)**\n",
    "\n",
    "Goal: Understand how the model \"thinks\" about what it just saw.  \n",
    "Key Concept: Expansion (64 \\-\\> 256\\) and Contraction (256 \\-\\> 64).\n",
    "\n",
    "1. **Extract the FFN:** let ff \\= feedForward firstBlock.  \n",
    "2. **Run it:** Pass the output of Attention into forwardFF.  \n",
    "3. **Shape Check:** Notice that the shape **does not change** (\\[1, 5, 64\\]). The FFN processes every token *independently* (unlike Attention, which mixes them).  \n",
    "4. **LayerNorm:**  \n",
    "   * **Experiment:** Calculate the mean and variance of the tensor *before* and *after* forwardLayerNorm.  \n",
    "   * **Observation:** After norm, the numbers should be roughly in the range of \\-2 to \\+2. This keeps the math stable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d20b025-8121-4419-845d-851e7aeef7f0",
   "metadata": {},
   "source": [
    "### **Phase 4: The Output (Logits to Predictions)**\n",
    "\n",
    "Goal: Converting abstract vectors back to words.  \n",
    "Key Concept: The Unembedding Layer (Linear).\n",
    "\n",
    "1. **The Final Projection:** Run NN.forward (finalLayer model) lastState.  \n",
    "2. **Shape Change:** \\[1, 5, 64\\] $\\\\rightarrow$ \\[1, 5, VocabSize\\].  \n",
    "3. **The \"Next Word\" Game:**  \n",
    "   * Take the vector for the **last** token in the sequence (index 4).  \n",
    "   * Run F.softmax on it.  \n",
    "   * **Action:** Find the argmax (the highest probability index). Look that index up in your vocab.  \n",
    "   * **Verification:** Does the predicted word make grammatical sense following your prompt?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6d82b2-951b-4404-bdbf-e2cbf7b5536f",
   "metadata": {},
   "source": [
    "### **Phase 5: The Loop (Autoregression)**\n",
    "\n",
    "**Goal:** Watch the sequence grow.\n",
    "\n",
    "1. **Manual Step-by-Step:**  \n",
    "   * Start with \"The\". Run the model. Get \"wizard\".  \n",
    "   * **Manually** construct the new input \"The wizard\". Run the model. Get \"cast\".  \n",
    "   * **Manually** construct \"The wizard cast\".  \n",
    "2. **Why:** This tedious manual process forces you to understand exactly what the program loop in Main.hs does millions of times."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Haskell",
   "language": "haskell",
   "name": "haskell"
  },
  "language_info": {
   "codemirror_mode": "ihaskell",
   "file_extension": ".hs",
   "mimetype": "text/x-haskell",
   "name": "haskell",
   "pygments_lexer": "Haskell",
   "version": "9.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
