{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42947b03-cf35-4e16-8751-92e444006f28",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Overview\n",
    "\n",
    "| Step | Function to Call | What to Inspect |\n",
    "| :---- | :---- | :---- |\n",
    "| **1\\. Input** | forwardEmbedding | Shapes, verify vectors are non-zero. |\n",
    "| **2\\. Mask** | makeCausalMask | **Visualize:** Ensure it is a triangle. |\n",
    "| **3\\. Attention** | forwardMHADebug | **Visualize:** attnWeights. Are they focusing on relevant past words? |\n",
    "| **4\\. Norms** | forwardLayerNorm | Check Mean/StdDev (should be \\~0 and \\~1). |\n",
    "| **5\\. Prediction** | finalLayer | argmax of the last token. Is it a real word? |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef40789-1728-4d5d-a638-22f7ae0fe48f",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f94dc237-33b3-48a3-9800-780434e5d0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "{-# LANGUAGE OverloadedStrings #-}\n",
    "\n",
    "import Torch (DType, Device, Parameter, Tensor, asTensor, defaultOpts, makeIndependent, ones, ones', toDependent, zeros, zeros')\n",
    "import qualified Torch as Th\n",
    "import qualified Torch.Autograd as TA\n",
    "import qualified Torch.Functional as F\n",
    "import qualified Torch.Functional.Internal as FI\n",
    "import qualified Torch.NN as NN\n",
    "import qualified Torch.Optim as Optim\n",
    "import qualified Torch.Serialize as Serialize\n",
    "import qualified Data.Set.Ordered as OSet\n",
    "import qualified Control.Foldl as L\n",
    "import qualified Data.Text as T\n",
    "import Data.Maybe (fromMaybe)\n",
    "import Text.Printf\n",
    "import IHaskell.Display\n",
    "import DecoderTransformer\n",
    "\n",
    "-- 1. Define both files used during training\n",
    "let trainFile = \"rpg-training-tokenized.txt\"\n",
    "let evalFile = \"rpg-evaluation-tokenized.txt\"\n",
    "\n",
    "-- 2. Load both files\n",
    "vocabParts <- traverse buildVocabFromFile [trainFile, evalFile]\n",
    "\n",
    "-- 3. Merge them AND add the [PAD] token (Crucial step!)\n",
    "-- This matches the logic in your compiled program\n",
    "let vocab = L.fold (L.Fold (OSet.|<>) (OSet.singleton \"[PAD]\") id) vocabParts\n",
    "let vocabSize = OSet.size vocab\n",
    "\n",
    "-- 4. Initialize an empty model structure\n",
    "model <- initModel vocabSize\n",
    "\n",
    "-- 2. Load the trained weights from the file created by 'stack run'\n",
    "loadedTensors <- Serialize.load \"rpg_model.pt\"\n",
    "\n",
    "-- 3. Hydrate the model\n",
    "loadedParams <- mapM makeIndependent loadedTensors\n",
    "let trainedModel = Th.replaceParameters model loadedParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "30c3e714-449a-4be7-9b67-e9758534a410",
   "metadata": {},
   "outputs": [],
   "source": [
    "{-# LANGUAGE RecordWildCards #-}\n",
    "\n",
    "forwardEmbedding :: TransformerModel -> Th.Tensor -> Th.Tensor\n",
    "forwardEmbedding TransformerModel {..} input = \n",
    "  let w = toDependent embedWeights\n",
    "      emb = F.embedding False False w paddingIdx input\n",
    "      \n",
    "      -- Get current sequence length from input shape [Batch, SeqLen]\n",
    "      currentSeqLen = Th.size 1 input\n",
    "      \n",
    "      -- Unwrap and Slice Positional Encoding\n",
    "      -- From: [1, 64, 64] -> To: [1, 5, 64]\n",
    "      fullPos = toDependent posEncoding\n",
    "      slicedPos = Th.sliceDim 1 0 currentSeqLen 1 fullPos\n",
    "      \n",
    "  in emb + slicedPos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af1766b-e20e-4bac-9971-19536267f39f",
   "metadata": {},
   "source": [
    "### **Phase 1: The Input Stage (Shape Shifting)**\n",
    "\n",
    "Goal: Understand how text becomes geometry.  \n",
    "Key Concept: \\[Batch, Seq\\] $\\rightarrow$ \\[Batch, Seq, EmbedDim\\]\n",
    "\n",
    "1. **Inspect the Vocabulary:** Pick 5 words and find their indices manually.  \n",
    "2. **Run Embeddings:** Use your forwardEmbedding helper.  \n",
    "   * **Investigation:** Print the shape. It should be \\[1, 5, 64\\].  \n",
    "   * **Sanity Check:** Print embedding\\[0\\]\\[0\\] (the vector for the first word) and embedding\\[0\\]\\[1\\] (the second). They should be completely different sets of numbers.  \n",
    "3. **Positional Encoding:**  \n",
    "   * **Action:** Extract posEncoding from the model.  \n",
    "   * **Experiment:** Verify that the vector at position 0 is different from the vector at position 1\\. Without this, the model sees \"The dog bit the man\" and \"The man bit the dog\" as identical \"bags of words.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "baa0c3d4-c554-4522-bd7a-b29762921b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,128,13,126,139]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1,5,64]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tensor Float [5] [-7.3626e-3,  3.7367e-2, -3.4854e-2, -9.8547e-2, -6.7193e-2]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tensor Float [5] [ 6.7673e-2, -2.2636e-4, -5.7980e-2,  1.9481e-3, -4.4925e-2]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1,5,64]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tensor Float [5] [-2.9523e-2, -1.7858e-2, -1.9255e-3, -1.4800e-2,  4.0148e-3]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tensor Float [5] [-3.7810e-3, -1.0424e-2,  1.2837e-2,  9.9363e-5, -1.9342e-2]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "{-# LANGUAGE OverloadedStrings #-}\n",
    "\n",
    "-- Indices of 5 words\n",
    "let fiveWords = [\"if\", \"else\", \"endif\", \"eval\", \"callp\"] :: [T.Text]\n",
    "let wordIdxs = map (\\w -> fromMaybe 0 (OSet.findIndex w vocab)) fiveWords\n",
    "print wordIdxs\n",
    "\n",
    "-- embedding shape\n",
    "let wordsTensor = Th.reshape [1,5] $ asTensor wordIdxs\n",
    "let weights = toDependent (embedWeights trainedModel)\n",
    "let emb = F.embedding False False weights 0 wordsTensor \n",
    "print (Th.shape emb)\n",
    "\n",
    "-- \"if\" embedding\n",
    "let ifEmb = Th.select 0 0 $ Th.select 0 0 emb\n",
    "print $ Th.sliceDim 0 0 5 1 ifEmb\n",
    "\n",
    "-- \"else\" embedding\n",
    "let elseEmb = Th.select 0 1 $ Th.select 0 0 emb\n",
    "print $ Th.sliceDim 0 0 5 1 elseEmb\n",
    "\n",
    "-- positional encoding\n",
    "let fullPosEnc = toDependent $ posEncoding trainedModel\n",
    "let posEnc = Th.sliceDim 1 0 5 1 fullPosEnc\n",
    "print $ Th.shape posEnc\n",
    "\n",
    "-- first word in sequence encoding\n",
    "let pos1 = Th.select 0 0 $ Th.select 0 0 posEnc\n",
    "print $ Th.sliceDim 0 0 5 1 pos1\n",
    "\n",
    "-- second word in sequence encoding\n",
    "let pos2 = Th.select 0 1 $ Th.select 0 0 posEnc\n",
    "print $ Th.sliceDim 0 0 5 1 pos2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2651d92b-7736-442d-a90f-978c30c600d0",
   "metadata": {},
   "source": [
    "### **Phase 2: The Heart (Multi-Head Attention)**\n",
    "\n",
    "Goal: Understand how tokens \"talk\" to each other.  \n",
    "Key Concept: $Q, K, V$ and the Causal Mask.\n",
    "\n",
    "1. **Use forwardMHADebug:** Pass your embeddings from Phase 1 into this function.  \n",
    "2. **Inspect Q, K, V:**  \n",
    "   * We project the input \\[64\\] into three different spaces.  \n",
    "   * **Action:** Check that $Q$ and $K$ have the same dimensions (so they can be multiplied).  \n",
    "3. **The \"Raw\" Scores (Affinity):**  \n",
    "   * Modify forwardMHADebug to return scoresRaw (before Softmax).  \n",
    "   * **Visual:** If you visualize this, the values will be wild (large positives and negatives).  \n",
    "4. **The Causal Mask (The Triangle):**  \n",
    "   * **Visual:** Use visualizeAttention on the mask tensor itself. You **must** see a solid triangle of \\-inf (or very large negative numbers) in the upper right.  \n",
    "   * **Why:** This proves the model cannot \"cheat\" by looking at future words.  \n",
    "5. **The Probability Map (Softmax):**  \n",
    "   * **Visual:** Look at attnWeights. The rows must sum to 1.0. This tells you: *For the word at position 3, how much does it care about positions 0, 1, and 2?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4ee0df-8d0e-468f-811f-b92fea07ad20",
   "metadata": {},
   "source": [
    "### **Phase 3: The Body (Feed Forward & Norms)**\n",
    "\n",
    "Goal: Understand how the model \"thinks\" about what it just saw.  \n",
    "Key Concept: Expansion (64 \\-\\> 256\\) and Contraction (256 \\-\\> 64).\n",
    "\n",
    "1. **Extract the FFN:** let ff \\= feedForward firstBlock.  \n",
    "2. **Run it:** Pass the output of Attention into forwardFF.  \n",
    "3. **Shape Check:** Notice that the shape **does not change** (\\[1, 5, 64\\]). The FFN processes every token *independently* (unlike Attention, which mixes them).  \n",
    "4. **LayerNorm:**  \n",
    "   * **Experiment:** Calculate the mean and variance of the tensor *before* and *after* forwardLayerNorm.  \n",
    "   * **Observation:** After norm, the numbers should be roughly in the range of \\-2 to \\+2. This keeps the math stable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d20b025-8121-4419-845d-851e7aeef7f0",
   "metadata": {},
   "source": [
    "### **Phase 4: The Output (Logits to Predictions)**\n",
    "\n",
    "Goal: Converting abstract vectors back to words.  \n",
    "Key Concept: The Unembedding Layer (Linear).\n",
    "\n",
    "1. **The Final Projection:** Run NN.forward (finalLayer model) lastState.  \n",
    "2. **Shape Change:** \\[1, 5, 64\\] $\\\\rightarrow$ \\[1, 5, VocabSize\\].  \n",
    "3. **The \"Next Word\" Game:**  \n",
    "   * Take the vector for the **last** token in the sequence (index 4).  \n",
    "   * Run F.softmax on it.  \n",
    "   * **Action:** Find the argmax (the highest probability index). Look that index up in your vocab.  \n",
    "   * **Verification:** Does the predicted word make grammatical sense following your prompt?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6d82b2-951b-4404-bdbf-e2cbf7b5536f",
   "metadata": {},
   "source": [
    "### **Phase 5: The Loop (Autoregression)**\n",
    "\n",
    "**Goal:** Watch the sequence grow.\n",
    "\n",
    "1. **Manual Step-by-Step:**  \n",
    "   * Start with \"The\". Run the model. Get \"wizard\".  \n",
    "   * **Manually** construct the new input \"The wizard\". Run the model. Get \"cast\".  \n",
    "   * **Manually** construct \"The wizard cast\".  \n",
    "2. **Why:** This tedious manual process forces you to understand exactly what the program loop in Main.hs does millions of times."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Haskell",
   "language": "haskell",
   "name": "haskell"
  },
  "language_info": {
   "codemirror_mode": "ihaskell",
   "file_extension": ".hs",
   "mimetype": "text/x-haskell",
   "name": "haskell",
   "pygments_lexer": "Haskell",
   "version": "9.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
